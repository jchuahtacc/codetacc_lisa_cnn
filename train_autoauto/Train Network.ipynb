{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network\n",
    "\n",
    "This notebook trains a Convolutional Neural Network using categorized images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages\n",
    "\n",
    "This notebook requires `Pillow`, `tensorflow` and `keras`. You may uncomment and run the cell below to have Jupyter Notebook install these for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Pillow, tensorflow, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Set the variables below to specify where the categorical images are located, which classes to train and what the filename should be for saved training data. If you would like to train all 45+ categories, set `classes = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_path = 'capture_data'\n",
    "\n",
    "# Uncomment this to train all categories\n",
    "classes = os.listdir(image_path)\n",
    "checkpoint_path = 'weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image\n",
    "from PIL import Image\n",
    "import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(64, 64, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(classes), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174 images belonging to 7 classes.\n",
      "Found 40 images belonging to 7 classes.\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 5s 822ms/step - loss: 1.8799 - acc: 0.3511 - val_loss: 1.7906 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.42500, saving model to weights-improvement-01-0.42.hdf5\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 4s 659ms/step - loss: 1.8147 - acc: 0.3876 - val_loss: 1.7233 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 4s 637ms/step - loss: 1.6948 - acc: 0.4044 - val_loss: 1.5886 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 4s 634ms/step - loss: 1.6718 - acc: 0.4097 - val_loss: 1.4971 - val_acc: 0.5250\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.42500 to 0.52500, saving model to weights-improvement-04-0.53.hdf5\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 4s 670ms/step - loss: 1.5741 - acc: 0.4524 - val_loss: 1.3988 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 4s 663ms/step - loss: 1.4861 - acc: 0.4630 - val_loss: 1.3434 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 4s 652ms/step - loss: 1.4733 - acc: 0.4506 - val_loss: 1.3041 - val_acc: 0.5250\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 4s 655ms/step - loss: 1.5062 - acc: 0.4198 - val_loss: 1.3662 - val_acc: 0.4750\n",
      "\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 6s 945ms/step - loss: 1.4002 - acc: 0.5110 - val_loss: 1.2259 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 5s 790ms/step - loss: 1.3408 - acc: 0.5000 - val_loss: 1.2927 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.52500 to 0.55000, saving model to weights-improvement-10-0.55.hdf5\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max',period=1)\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale = 1.0 / 255.0,  \n",
    "                                 rotation_range=10, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                 zoom_range=0.2,shear_range=20,\n",
    "                                 validation_split=0.2)\n",
    "\n",
    "    training_set = datagen.flow_from_directory(image_path, classes=classes, target_size=(64, 64), \n",
    "                                               color_mode='grayscale', batch_size=32, shuffle=True,\n",
    "                                               subset=\"training\")\n",
    "    validation_set = datagen.flow_from_directory(image_path, classes=classes, target_size=(64, 64), \n",
    "                                               color_mode='grayscale', batch_size=32, shuffle=True,\n",
    "                                               subset=\"validation\")\n",
    "\n",
    "    history = model.fit_generator(training_set,\n",
    "                                  validation_data=validation_set,\n",
    "                                  epochs=10, verbose=1, callbacks=[ checkpoint ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(weightfile):\n",
    "    from keras.models import load_model\n",
    "    model = load_model(weightfile)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_trained_model(\"weights-improvement-10-0.55.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread(\"capture_data/forward/Groot1529091688.png\", 0)\n",
    "image = np.array([ image.reshape(64, 64, 1) ])\n",
    "print(classes[trained_model.predict_classes(image)[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
